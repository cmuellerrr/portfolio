---
layout: post
categories: work
featured: true
directory: peer
title: "PEER"
tagline: "A head-mounted procedure viewer for the International Space Station."
tagline-short: "Head-mounted procedure viewer."
classification: "Wearable"
team:
  - <a href="http://www.stephentrahan.com">Stephen Trahan</a>
  - <a href="http://www.j6tran.com">Jenn Tran</a>
  - <a href="http://www.kristinalustig.com">Kristina Lustig</a>
  - <a href="http://www.gordonsliu.com">Gordon Liu</a>
role: Technical lead
completed: Aug 2013
length: 8 months
tools: Java, Android, Processing, Adobe Illustrator
repo: https://www.github.com/cmuellerrr/PEER
site: http://www.hcii.cmu.edu/M-HCI/2013/novo/
---

<section>
    <h2>Summary</h2>
    <p>Astronauts on the International Space Station (ISS) follow procedures for everything. Those procedures, and the mechanism for viewing them, aren't great. As a graduate project working with the NASA Ames Research Center, we built a head-mounted procedure viewer prototype in order to address some of the issues with crew member efficiency.</p>

    <div class="figure">
        <div class="videoWrapper">
            <iframe src="//player.vimeo.com/video/72005257?byline=0&amp;portrait=0" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
        </div>
    </div>

    <p class="continue">Keep reading for more details on our process</p>
</section>

<section>
    <h2>The challenge</h2>
    <p>Crew members on the ISS spend most of their time carrying out scientific research. For each research task, they must follow a rigid, complex procedure. The procedures, and the way they are used, cause a considerable reduction in efficiency; procedures are static text documents and are only viewable on wall-mounted laptops throughout the station.</p>

    <div class="figure">
        <img src="/assets/images/peer/iss_interior.jpg"\>
        <p class="caption">The ISS isn't exactly simple, or tidy, or easy to work with, etc. Image courtesy of NASA</p>
    </div>

    <p>Every project needs a mission statement, right? Right.</p>

    <p><b>We set out to explore operator workflow in isolated environments in order to optimize procedure execution.</b></p>
</section>

<section>
    <h2>Building domain knowledge</h2>
    <p>A lot of the time, designers have some background knowledge of the domain they are designing for. That's not really the case when it comes to working on a space station. So to better inform our approach, we started with a literature review on topics like the psychology of spaceflight, the structure of the ISS, and the cognitive processing of tasks.</p>

    <!--
    <ul>
        <li>Checklists are great for complex, high-stress fields of work.</li>
        <li>Augmented reality has been shown to increase task efficiency.</li>
        <li>Multitasking and high mental workload can have a detrimental effect on performance.</li>
        <li>Living in 0G can be fatiguing, anxiety-inducing, and physically taxing.</li>
    </ul>
    -->

    <p>We paired the literature review with a competitive analysis of other procedure-like tools such as medical procedure viewers, websites like Instructables.com, as well as the viewer currently in use on the ISS. Here, we focused on portability, rich media, customization, contextual awareness, and tool retrieval. Our analysis led us to a few recommendations:</p>

    <ul>
        <li>Consider wearable computing and voice control as options for portable, hands-free procedure viewing.</li>
        <li>Explore the potential of augmented reality for overlaying directions on a user's field of view.</li>
        <li>Leverage the experience of workers in order to improve procedure content through comments and annotations.</li>
        <li>Utilize current environmental and task conditions to provide relevant procedural information.</li>
        <li>Automate the tool identification and stowage process.</li>
    </ul>
</section>

<section>
    <h2>Unreachable users</h2>
    <p>Designing tools for astronauts has a unique constraint in that you will never be able to do contextual research due to the prohibitive cost of sending designers to space. So, we had to make due by talking to anyone we could get our hands on.</p>

    <p>We interviewed NASA experts within organizations like Operations Planning, Payload Science, and Wearable Computing to build up even more domain knowledge. We were also extremely fortunate to interview two astronauts with mission experience - one retired and one less than 6 months removed from commanding the ISS<sup><a id="ref1" href="#fn1" title="Jump to footnote.">1</a></sup>.</p>

    <div class="quote">
        <p>If they looked at the procedure and saw that it was 20 pages long, literally, they'd be like, 'It's going to take me longer to read the procedure than to just do what I need to do.'</p>
        <p class="attribution">- Procedure writer</p>
    </div>

    <p>Since we couldn't research our end users in context, we went on a nation-wide search to perform contextual research with individuals whose work was similar to the ISS crew in some way. We met with commercial pilots, deep sea divers, lab technicians, paramedics, construction managers, and pit crews based on similarities their tasks shared with payload science and maintenance work.</p>

    <div class="figure">
        <img src="/assets/images/peer/card_mapping.jpg"\>
        <p class="caption">We asked commercial pilots to visualize their workflow through a card mapping excercise.</p>
    </div>
</section>


<section>
    <h2>Extracting insights and visioning</h2>
    <p>Naturally, we synthesized our research through affinity diagrams (one domain-specific and one for analogous domains) and various other models (i.e. cultural, sequence, artifact). From this, we extracted eight key issues to address:</p>

    <ul>
        <li><b>Portability</b> &mdash; Crew need to move around to complete tasks, but the procedure viewer is attached to a wall.</li>
        <li><b>Annotations</b> &mdash; Crew sometimes print out procedures to write on them instead of using the digital annotation feature.</li>
        <li><b>Hands-free</b> &mdash; Hands are needed to both navigate procedures and perform tasks simultaneously.</li>
        <li><b>Brevity</b> &mdash; Procedures are always displayed in full, but that's not always necessary.</li>
        <li><b>Visualization</b> &mdash; Current procedures are mostly text.</li>
        <li><b>Autonomy</b> &mdash; Crew aren't given to opportunity to be very autonomous, which will be critical to missions far from Earth.</li>
        <li><b>Training</b> &mdash; Training is focused on tasks rather than the underlying skills.</li>
        <li><b>Stowage</b> &mdash; Crew members spend a significant amount of time trying to find tools.</li>
    </ul>

    <div class="figure">
        <img src="/assets/images/peer/visioning.jpg"\>
        <p class="caption">So many notes. Our visioning sessions resulted in over 400 individual ideas.</p>
    </div>

    <p>After several visioning sessions and activities, we narrowed down our vision to one utilizing a head-mounted display<sup><a id="ref2" href="#fn2" title="Jump to footnote.">2</a></sup>. The HMD would allow for hands-free interaction through voice interaction and leverage augmented-reality (AR) to provide information in context within a crew's work environment.</p>

    <div class="figure">
        <img src="/assets/images/peer/rejected_vision.png"\>
        <p class="caption">One of our rejected visions had the crew using a wrist-worn device along with a tablet.</p>
    </div>
</section>

<section>
    <h2>Prototyping an HMD</h2>
    <p>Lo-fidelity testing, rapid iteration, available hardware - these are all things imperative to prototyping. These are also all things that HMDs utterly fail at. Basically, if you want to test an application on an HMD, you have to build it. That is dumb. So, we had to find a way to quickly iterate and get feedback without building out functional software each time.</p>

    <div class="figure">
        <img src="/assets/images/peer/testing_room.png"\>
        <p class="caption">We tested by having users run through a pretend procedure in our mockup space station.</p>
    </div>

    <p><a href="http://www.gordonsliu.com">Gordon</a> and I ended up building a prototyping tool that would let us use the actual HMD in tests but would display our wireframes instead of working software<sup><a id="ref3" href="#fn3" title="Jump to footnote.">3</a></sup>. This allowed us to test six iterations within a few weeks.</p>

    <p>The final version was designed to have a pretty simple, linear structure (while allowing users to jump to anywhere if desired). It splits steps into individual screens and provides in-context information and AR overlays to address the verbosity of current procedures.</p>

    <div class="figure">
        <img src="/assets/images/peer/ui_map.png"\>
        <p class="caption">A map of the prototype UI. Procedures are viewed linearly, but users can access other features through a menu.</p>
    </div>

    <div class="figure">
        <img src="/assets/images/peer/peer_ui.png"\>
        <p class="caption">A view of the prototype's interface from a user's perspective.</p>
    </div>
</section>

<section>
    <h2>Hardware limitations</h2>
    <p>For hardware, we chose to use the Epson Moverio due to it being one of the few available HMDs and its Affordability compared to the rest of the market. The down side is that the Moverio doesn't have any external sensors, so again we had to find a way to get what we needed. We ended up pairing the Moverio with a tablet to process all voice commands and handle the AR. The tablet then relayed what to display to the HMD. While not pretty &mdash; or ideal &mdash; it got the job done.</p>

    <div class="figure">
        <img src="/assets/images/peer/the_future.jpg"\>
        <p class="caption">The only time it ever looked kind of cool.</p>
    </div>
</section>

<section>
    <h2>What we learned</h2>
    <p>The final prototype was well received; gaining high marks in our final readiness test. I believe we also succeeded in exploring if an HMD is worth pursuing in the future. I think that it is, but the hardware just isn't ready yet<sup><a id="ref4" href="#fn4" title="Jump to footnote.">4</a></sup>.</p>

    <p>If you want to know more about the project, you can get additional information at <a href="{{ page.site }}">our project website</a>. The code for the final prototype, as well as our prototyping tools, is available on <a href="{{ page.repo }}">github</a>.</p>
</section>

<section class="footnotes">
    <p><sup id="fn1">1. Seriously, astronaut time is so valuable that being able to snag an hour was a huge win.<a href="#ref1" title="Jump to reference in the text.">&#8617;</a></sup></p>
    <p><sup id="fn2">2. While not only addressing many of the issues found, this project provided an opportunity to explore the feasibility of HMDs in a 0G environment.<a href="#ref2" title="Jump to reference in the text.">&#8617;</a></sup></p>
    <p><sup id="fn3">3. A moderator would sit at a computer during a test and serve static images to the HMD based on commands spoken by the tester.<a href="#ref3" title="Jump to reference in the text.">&#8617;</a></sup></p>
    <p><sup id="fn4">4. Most are unavailable, prohibitively expense, or not advanced enough to be useful.<a href="#ref4" title="Jump to reference in the text.">&#8617;</a></sup></p>
</section>
