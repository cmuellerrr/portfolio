---
layout: post
title: "Modal Nodes"
date: 2012-12-15
categories: 
excerpt: An interactive music installation for creating atmospheric soundscapes.
thumbnail: assets/images/modal_nodes/thumb.png
---

<div class="section row">
	<div class="five columns">
		<p>Modal Nodes is a large-scale music sequencer which uses the Microsoft Kinect to gather all input. In the environment, users are able to place nodes on the screen to produce atmospheric musical sequences.</p>
	</div>
	<div class="ten columns offset-by-one">
		<iframe class="fill" src="http://player.vimeo.com/video/69808942?byline=0&amp;portrait=0" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
	</div>
</div>

<div class="section row">
	<div class="five columns">
		<h3 class="title">User Study</h3>
		<p>A goal of this project was to test differences between gesture-based (movement over time) and pose-based (static) interactions. So, we set up several user tests throughout the development of the application to get concrete data. Participants were free to experiment with the system as they desired and were observed for physical difficulties, mental disconnects, and personal preferences.</p>

		<p>We found that gestures had good affordance yet caused higher levels of fatigue while the poses were easily performed but had low discoverability. While additional tuning could be used to overcome certain issues in both, we concluded that pose-based interactions were a more effective interactive technique for this application.</p>
	</div>
	<div class="ten columns offset-by-one">
		<img class="fill" src="/assets/images/modal_nodes/diagram.png">
		<img class="fill" src="/assets/images/modal_nodes/poses.png">
	</div>
</div>

<div class="section row">
	<div class="five columns">
		<h3 class="title">Affordances</h3>
		<p>With walk-up-and-use being a necessity, we needed to make sure that the interactions are both intuitive and easy to perform. One way we accomplish this is by having the environment react as a user approaches completing an action.</p>

		<p>For example, when users begin the process of creating a node, the normally ambient particles move away from the background and swarm around a user’s hands – the closer a user is to completing the action, the tighter and faster the particles swarmed.</p>
	</div>
	<div class="ten columns offset-by-one">
		<img class="fill" src="/assets/images/modal_nodes/ex1.png">
		<img class="fill" src="/assets/images/modal_nodes/ex2.png">
		<img class="fill" src="/assets/images/modal_nodes/ex3.png">
		<img class="fill" src="/assets/images/modal_nodes/ex4.jpg">
	</div>
</div>

<div class="section row">
	<div class="five columns">
		<h3 class="title">Audio</h3>
		<p>Modal Nodes is designed for public spaces. Therefore, we placed a significant emphasis on ensuring that the resulting audio sequence is pleasant in every case. We got this by utilizing a fairly long echo effect which allows the tones to blend together nicely and by staying away from sharp, abrasive tones.</p>
	</div>
	<div class="ten columns offset-by-one">
	</div>
</div>

<!--
<div class="section row">
	<div class="five columns">
		<h3 class="title">Improvements</h3>
		<p>Although pleased with our current implementation, we feel that our visualizations and interactions have not been fully realized. The interactions are not yet at a level in which the application could be used by a new user without some sort of instruction.  Furthermore, we seek to improve upon the audio processing capabilities of the system. Providing additional audio effects, either by having nodes interact with each other or through alteration of the nodes themselves, would provide further avenues for users to explore.</p>
	</div>
	<div class="ten columns offset-by-one">
	</div>
</div>
-->